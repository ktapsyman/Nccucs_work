from io import StringIO
import numpy as np 
import pandas as pd 

from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn import preprocessing, model_selection, metrics
from sklearn.svm import SVR

from gensim import utils
from gensim.models.doc2vec import TaggedLineDocument
from gensim.models import Doc2Vec

import lightgbm as lgb
import xgboost as xgb

BASE_DATA_DIR="/home/psyman/WorkSpace/ExtraSpace/Psyman/WSM/"
pd.options.mode.chained_assignment = None
pd.options.display.max_columns = 999

def ReadData(FileName):
	Fullpath = BASE_DATA_DIR + FileName
	return pd.read_csv(Fullpath, parse_dates=["activation_date"])

def EngRegion(Df):
	RegionMap = StringIO("""
region,region_en
???????????? ???????, Sverdlovsk oblast
????????? ???????, Samara oblast
?????????? ???????, Rostov oblast
?????????, Tatarstan
????????????? ???????, Volgograd oblast
????????????? ???????, Nizhny Novgorod oblast
???????? ????, Perm Krai
???????????? ???????, Orenburg oblast
?????-?????????? ??, Khanty-Mansi Autonomous Okrug
????????? ???????, Tyumen oblast
????????????, Bashkortostan
????????????? ????, Krasnodar Krai
????????????? ???????, Novosibirsk oblast
?????? ???????, Omsk oblast
???????????? ???????, Belgorod oblast
??????????? ???????, Chelyabinsk oblast
??????????? ???????, Voronezh oblast
??????????? ???????, Kemerovo oblast
??????????? ???????, Saratov oblast
???????????? ???????, Vladimir oblast
??????????????? ???????, Kaliningrad oblast
???????????? ????, Krasnoyarsk Krai
??????????? ???????, Yaroslavl oblast
????????, Udmurtia
????????? ????, Altai Krai
????????? ???????, Irkutsk oblast
?????????????? ????, Stavropol Krai
???????? ???????, Tula oblast
""")
	RegionDf = pd.read_csv(RegionMap)
	Df = pd.merge(Df, RegionDf, how="left", on="region")
	return Df

def EngParentCategory(Df):
	ParentCategoryMap = StringIO("""
parent_category_name,parent_category_name_en
?????? ????,Personal belongings
??? ???? ? ????,For the home and garden
??????? ???????????,Consumer electronics
????????????,Real estate
????? ? ?????,Hobbies & leisure
?????????,Transport
??????,Services
????????,Animals
??? ???????,For business
""")
	ParentCategoryDf = pd.read_csv(ParentCategoryMap)
	Df = pd.merge(Df, ParentCategoryDf, how="left", on="parent_category_name")
	return Df

def EngAdCategory(Df):
	AdCategoryMap = StringIO("""
category_name,category_name_en
"??????, ?????, ??????????","Clothing, shoes, accessories"
??????? ?????? ? ?????,Children's clothing and shoes
?????? ??? ????? ? ???????,Children's products and toys
????????,Apartments
????????,Phones
?????? ? ????????,Furniture and interior
??????????? ?????,Offer services
??????????,Cars
?????? ? ?????????????,Repair and construction
??????? ???????,Appliances
?????? ??? ??????????,Products for computer
"????, ????, ????????","Houses, villas, cottages"
??????? ? ????????,Health and beauty
????? ? ?????,Audio and video
????? ? ?????,Sports and recreation
??????????????????,Collecting
???????????? ??? ???????,Equipment for business
????????? ???????,Land
???? ? ?????????,Watches and jewelry
????? ? ???????,Books and magazines
??????,Dogs
"????, ????????? ? ?????????","Games, consoles and software"
?????? ????????,Other animals
??????????,Bikes
????????,Laptops
?????,Cats
????????? ? ???????????,Trucks and buses
?????? ? ?????? ??? ?????,Tableware and goods for kitchen
????????,Plants
???????? ? ??????????? ?????,Tablets and e-books
?????? ??? ????????,Pet products
???????,Room
???????????,Photo
???????????? ????????????,Commercial property
?????? ? ???????????,Garages and Parking spaces
??????????? ???????????,Musical instruments
?????????? ? ??????????,Office equipment and consumables
?????,Birds
???????? ???????,Food
????????? ? ???????????,Motorcycles and bikes
?????????? ??????????,Desktop computers
????????,Aquarium
????? ? ???????,Hunting and fishing
?????? ? ???????????,Tickets and travel
?????? ?????????,Water transport
??????? ??????,Ready business
???????????? ?? ???????,Property abroad
""")
	AdCategoryDf = pd.read_csv(AdCategoryMap)
	Df = pd.merge(Df, AdCategoryDf, how="left", on="category_name")

	return Df

def run_lgb(train_X, train_y, val_X, val_y, test_X):
    params = {
        "objective" : "regression",
        "metric" : "rmse",
        "num_leaves" : 30,
        "learning_rate" : 0.1,
        "bagging_fraction" : 0.7,
        "feature_fraction" : 0.7,
        "bagging_frequency" : 5,
        "bagging_seed" : 2018,
        "verbosity" : -1
    }
    
    lgtrain = lgb.Dataset(train_X, label=train_y)
    lgval = lgb.Dataset(val_X, label=val_y)
    evals_result = {}
    model = lgb.train(params, lgtrain, 1000, valid_sets=[lgval], early_stopping_rounds=100, verbose_eval=20, evals_result=evals_result)
    
    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)
    return pred_test_y, model, evals_result

train_df = ReadData("train.csv")
train_df = EngRegion(train_df)
train_df = EngParentCategory(train_df)
train_df = EngAdCategory(train_df)

test_df = ReadData("test.csv")
test_df = EngRegion(test_df)
test_df = EngParentCategory(test_df)
test_df = EngAdCategory(test_df)

print(train_df.isnull().sum())
print(test_df.isnull().sum())
print("Train file rows and columns are : ", train_df.shape)
print("Test file rows and columns are : ", test_df.shape)
#print(train_df.head)

Bow_train = train_df['title'].values.tolist()
Bow_test = test_df['title'].values.tolist()
Bow = Bow_train+Bow_test
#Doc2Vec approach
Docs = TaggedLineDocument(Bow)
Doc2VecModel = Doc2Vec(Docs, min_count=1, window=10, vector_size=10)
Doc2VecModel.train(Docs)
Doc2VecModel.save("Title.model")
with open("Doc2Vec.vec", "w") as VecOutputFile:
	for Vec in Doc2VecModel.docvecs:
		VecOutputFile.write(Vec)
	
print("End of building Doc2Vec")

### TFIDF Vectorizer ###

tfidf_vec = TfidfVectorizer(ngram_range=(1,1))
full_tfidf = tfidf_vec.fit_transform(Bow_train+Bow_test)
train_tfidf = tfidf_vec.transform(Bow_train)
test_tfidf = tfidf_vec.transform(Bow_test)

print("End of TFIDF")

### SVD Components ###
n_comp = 3
svd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')
svd_obj.fit(full_tfidf)
train_svd = pd.DataFrame(svd_obj.transform(train_tfidf))
test_svd = pd.DataFrame(svd_obj.transform(test_tfidf))
train_svd.columns = ['svd_title_'+str(i+1) for i in range(n_comp)]
test_svd.columns = ['svd_title_'+str(i+1) for i in range(n_comp)]
train_df = pd.concat([train_df, train_svd], axis=1)
test_df = pd.concat([test_df, test_svd], axis=1)
del full_tfidf, train_tfidf, test_tfidf, train_svd, test_svd

## Filling missing description values ##
train_df["description"].fillna("NA", inplace=True)
test_df["description"].fillna("NA", inplace=True)

train_df["desc_nwords"] = train_df["description"].apply(lambda x: len(x.split()))
test_df["desc_nwords"] = test_df["description"].apply(lambda x: len(x.split()))

# Target and ID variables #
train_y = train_df["deal_probability"].values
test_id = test_df["item_id"].values

# New variable on weekday #
train_df["activation_weekday"] = train_df["activation_date"].dt.weekday
test_df["activation_weekday"] = test_df["activation_date"].dt.weekday

# Has image
train_df["has_image"] = train_df["image"].apply(lambda x:1 if x is not None else -1)
test_df["has_image"] = test_df["image"].apply(lambda x:1 if x is not None else -1)

# Label encode the categorical variables #
cat_vars = ["region", "city", "parent_category_name", "category_name", "user_type", "param_1", "param_2", "param_3"]
for col in cat_vars:
    lbl = preprocessing.LabelEncoder()
    lbl.fit(list(train_df[col].values.astype('str')) + list(test_df[col].values.astype('str')))
    train_df[col] = lbl.transform(list(train_df[col].values.astype('str')))
    test_df[col] = lbl.transform(list(test_df[col].values.astype('str')))

cols_to_drop = ["item_id", "user_id", "title", "description", "activation_date", "image"]
train_X = train_df.drop(cols_to_drop + ["region_en", "parent_category_name_en", "category_name_en", "deal_probability"], axis=1)
test_X = test_df.drop(cols_to_drop+["region_en", "parent_category_name_en", "category_name_en"], axis=1)

#print(train_X.head())
# Splitting the data for model training#
dev_X = train_X.iloc[:-200000,:]
val_X = train_X.iloc[-200000:,:]
dev_y = train_y[:-200000]
val_y = train_y[-200000:]
print(dev_X.shape, val_X.shape, test_X.shape)

# Training the model #
pred_test, model, evals_result = run_lgb(dev_X, dev_y, val_X, val_y, test_X)
"""
Classifiers = [xgb.XGBRegressor(max_depth=20, n_estimators=300, learning_rate=0.05)]
ResultDict = {}
for clf in Classifiers:
	name = clf.__class__.__name__
	clf.fit(dev_X, dev_y, eval_metric='rmse')
	train_predictions = clf.predict(val_X)
	rmse = metrics.mean_squared_error(val_y, train_predictions) ** 0.5
	if name in ResultDict:
		ResultDict[name] += rmse
	else:
		ResultDict[name] = rmse

for clf in ResultDict:
	print(ResultDict[clf])
	print("===================================")
"""

# Making a submission file #
pred_test[pred_test>1] = 1
pred_test[pred_test<0] = 0
sub_df = pd.DataFrame({"item_id":test_id})
sub_df["deal_probability"] = pred_test
sub_df.to_csv("Prediction.csv", index=False)
